{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref: https://github.com/meta-toolkit/metapy/blob/master/tutorials/1-analyzers-tokenizers-filters.ipynb\n",
    "import metapy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install metapy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en google colab:\n",
    "# ana = metapy.analyzers.load('gdrive/MyDrive/st1800github/out/meta/ejemplo1-metapy/config.toml')\n",
    "#\n",
    "ana = metapy.analyzers.load('config.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../wikipedia-en-1.csv',delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = metapy.index.Document()\n",
    "tok = metapy.analyzers.ICUTokenizer()\n",
    "tok = metapy.analyzers.LowercaseFilter(tok)\n",
    "def split(r):\n",
    "    tok.set_content(r)\n",
    "    lista = [t for t in tok]\n",
    "    return lista[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_title'] = df.apply(lambda row:  split(str(row['title'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_title'] = df.apply(lambda row: len(row['tokenized_title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_content'] = df.apply(lambda row:  split(str(row['content'])), axis=1)\n",
    "df['count_content'] = df.apply(lambda row: len(row['tokenized_content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize todo el contenido de 'title'\n",
    "all_tokens_title = []\n",
    "for t in df['tokenized_title']:\n",
    "    all_tokens_title.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all_tokens_title =\",len(all_tokens_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize todo el contenido de 'content'\n",
    "all_tokens_content = []\n",
    "for t in df['tokenized_content']:\n",
    "    all_tokens_content.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo el contenido de 'content'\n",
    "all_content = []\n",
    "for t in df['content']:\n",
    "    all_content.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all_tokens_content =\",len(all_tokens_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = metapy.index.Document()\n",
    "doc2.content(\"I said edwin the that it only I can't believe that it only costs $19.95!\")\n",
    "#doc2.content(all_content)\n",
    "tok2 = metapy.analyzers.ICUTokenizer()\n",
    "tok2 = metapy.analyzers.LowercaseFilter(tok2)\n",
    "tok2 = metapy.analyzers.ListFilter(tok2, \"lemur-stopwords.txt\", metapy.analyzers.ListFilter.Type.Reject)\n",
    "tok2.set_content(doc2.content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in tok2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana.analyze(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = metapy.analyzers.NGramWordAnalyzer(1, tok2)\n",
    "ana.analyze(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = metapy.analyzers.NGramWordAnalyzer(2, tok2)\n",
    "ana.analyze(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = metapy.analyzers.NGramWordAnalyzer(3, tok2)\n",
    "ana.analyze(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer un archivo de ejemplo en .txt\n",
    "input_file = open(\"../war-and-peace.txt\", \"r\")\n",
    "filedata = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = metapy.index.Document()\n",
    "#doc.content(\"I said edwin the that it only I can't believe that it only costs $19.95!\")\n",
    "doc.content(filedata)\n",
    "tok = metapy.analyzers.ICUTokenizer()\n",
    "tok = metapy.analyzers.LowercaseFilter(tok)\n",
    "tok = metapy.analyzers.ListFilter(tok, \"lemur-stopwords.txt\", metapy.analyzers.ListFilter.Type.Reject)\n",
    "tok.set_content(doc.content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = metapy.analyzers.NGramWordAnalyzer(1, tok)\n",
    "ngrams = ana.analyze(doc)\n",
    "print(len(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_x = sorted(ngrams.items(), key=operator.itemgetter(0),reverse=True)\n",
    "#sorted_x = sorted(ngrams, key=ngrams.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = metapy.analyzers.NGramWordAnalyzer(2, tok)\n",
    "bigrams = ana.analyze(doc)\n",
    "print(len(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok3.set_content(doc3.content())\n",
    "ana = metapy.analyzers.NGramWordAnalyzer(1, tok3)\n",
    "unigrams = ana.analyze(doc3)\n",
    "print(len(unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok3.set_content(doc3.content())\n",
    "ana = metapy.analyzers.NGramWordAnalyzer(2, tok3)\n",
    "unigrams = ana.analyze(doc3)\n",
    "print(len(unigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdftotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObject = open(r\"/Users/emontoya/Downloads/2004.14103.pdf\", 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" No. Of Pages :\", pdfReader.numPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageObject = pdfReader.getPage(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pageObject.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdftotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "\n",
    "file = '/Users/emontoya/Downloads/2004.14103.pdf'\n",
    "# Parse data from file\n",
    "file_data = parser.from_file(file)\n",
    "# Get files text content\n",
    "text = file_data['content']\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}